{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Code example: Analyzing which factors (from weather and location data) influence peope to ride the subway more.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The question: Do more people ride the subway when it is rainy, foggy, and cold outside?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Method: Linear regression with gradient descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##What the code does: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Computes the cost (aka loss) i.e. how far off are the predictions from the current prediction line created by linear regression to fit the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Uses gradient descent algorithm to optimize the weights of each feature (rain, fog, minimum temperature) in the equation used to fit the regression line to the observed data points(this data is the from NYC Subway dataset and Weather Underground API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Prints out an R squared value (between 0 and 1; tells us how much of the variation in our dependent variable ( # of entries in the subway ) can be attributed to the variation in the features we decided to include in the model (rain, fog, minimum temperature on that day, the time of day, which data collection unit or subway station collected the entry data, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 = 0.458183884318\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize_features(array):\n",
    "   \"\"\"\n",
    "   Normalize the features in our data set.\n",
    "   \"\"\"\n",
    "   array_normalized = (array-array.mean())/array.std()\n",
    "   mu = array.mean()\n",
    "   sigma = array.std()\n",
    "\n",
    "   return array_normalized, mu, sigma\n",
    "\n",
    "def compute_cost(features, values, theta):\n",
    "    \"\"\"\n",
    "    Compute the cost function given a set of features / values, and the values for our thetas.\n",
    "    \n",
    "    This should be the same code as the compute_cost function in the lesson #3 exercises. But\n",
    "    feel free to implement your own.\n",
    "    \"\"\"\n",
    "    \n",
    "    #\n",
    "    # your code here\n",
    "    #\n",
    "    m = len(values)\n",
    "    sum_of_square_errors = np.square(np.dot(features, theta) - values).sum()\n",
    "    cost = sum_of_square_errors / (2*m)\n",
    "    return cost\n",
    "\n",
    "def gradient_descent(features, values, theta, alpha, num_iterations):\n",
    "    \"\"\"\n",
    "    Perform gradient descent given a data set with an arbitrary number of features.\n",
    "    \n",
    "    This is the same gradient descent code as in the lesson #3 exercises. But feel free\n",
    "    to implement your own.\n",
    "    \"\"\"\n",
    "    m = len(values)\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # \n",
    "        # your code here\n",
    "        predicted_values = np.dot(features, theta)\n",
    "        theta = theta - (alpha / m) * np.dot((predicted_values - values), features)\n",
    "            \n",
    "        cost = compute_cost(features, values, theta)\n",
    "        cost_history.append(cost)\n",
    "    return theta, pd.Series(cost_history)\n",
    "\n",
    "def predictions(dataframe):\n",
    "    '''\n",
    "    The NYC turnstile data is stored in a pd dataframe called weather_turnstile.\n",
    "    Using the information stored in the dataframe, lets predict the ridership of\n",
    "    the NYC subway using linear regression with gradient descent.\n",
    "    \n",
    "    You can look at information contained in the turnstile weather dataframe \n",
    "    at the link below:\n",
    "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv    \n",
    "    \n",
    "    Your prediction should have a R^2 value of .40 or better.\n",
    "    \n",
    "    Note: due to the memory and CPU limitation of our amazon EC2 instance, we will\n",
    "    give you a random subet (~15%) of the data contained in turnstile_data_master_with_weather.csv\n",
    "    \n",
    "    If you receive a \"server has encountered an error\" message, that means you are hitting \n",
    "    the 30 second  limit that's placed on running your program. Try using a smaller number\n",
    "    for num_iterations if that's the case.\n",
    "    \n",
    "    Or if you are using your own algorithm/modesl, see if you can optimize your code so it\n",
    "    runs faster.\n",
    "    '''\n",
    "\n",
    "    dummy_units = pd.get_dummies(dataframe['UNIT'], prefix='unit')\n",
    "    features = dataframe[['rain', 'precipi', 'Hour', 'mintempi', 'fog']].join(dummy_units)\n",
    "    values = dataframe[['ENTRIESn_hourly']]\n",
    "    m = len(values)\n",
    "\n",
    "    features, mu, sigma = normalize_features(features)\n",
    "\n",
    "    features['ones'] = np.ones(m)\n",
    "    features_array = np.array(features)\n",
    "    values_array = np.array(values).flatten()\n",
    "\n",
    "    #Set values for alpha, number of iterations.\n",
    "    alpha = 0.1 # please feel free to play with this value\n",
    "    num_iterations = 75 # please feel free to play with this value\n",
    "\n",
    "    #Initialize theta, perform gradient descent\n",
    "    theta_gradient_descent = np.zeros(len(features.columns))\n",
    "    theta_gradient_descent, cost_history = gradient_descent(features_array, values_array, theta_gradient_descent, +\\\n",
    "                                                            alpha, num_iterations)\n",
    "    \n",
    "    \n",
    "    \n",
    "    predictions = np.dot(features_array, theta_gradient_descent)\n",
    "    \n",
    "   \n",
    "   \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def compute_r_squared(data, predictions):\n",
    "    SST = ((data-np.mean(data))**2).sum()\n",
    "    SSReg = ((predictions-np.mean(data))**2).sum()\n",
    "    r_squared = SSReg / SST\n",
    "\n",
    "    return r_squared\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_filename = \"turnstile_data_master_with_weather.csv\"\n",
    "    turnstile_master = pd.read_csv(input_filename)\n",
    "    predicted_values = predictions(turnstile_master)\n",
    "    r_squared = compute_r_squared(turnstile_master['ENTRIESn_hourly'], predicted_values) \n",
    "    \n",
    "    \n",
    "    print 'R^2 = ' + str(r_squared)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
